import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ã¦ã®ã»ã­ã‘ã‚“ã—ã‚…ã¤ã‚¢ãƒ—ãƒª", layout="centered")

# MediaPipe Hands åˆæœŸåŒ–
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# ã‚¿ã‚¤ãƒˆãƒ«
st.markdown("<h1 style='color: #4D90FE;'>ğŸ–ï¸ ã¦ã®ã»ã­ã‚’ ã¿ã¦ã¿ã‚ˆã†ï¼</h1>", unsafe_allow_html=True)
st.write("ãˆã„ãã†ã‚„ ã—ã‚ƒã—ã‚“ã‚’ ã‚¢ãƒƒãƒ—ã—ã¦ã­ã€‚")

# æ‰‹ã®æ¤œå‡ºï¼ˆç”»åƒç”¨ï¼‰
def detect_hand_image(image):
    with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7) as hands:
        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)
    return image

# æ‰‹ã®æ¤œå‡ºï¼ˆå‹•ç”»ç”¨ãƒ»è»½é‡åŒ–ï¼‰
def detect_hand_video(video_file):
    cap = cv2.VideoCapture(video_file)
    fps = cap.get(cv2.CAP_PROP_FPS)
    w, h = 640, 360  # âœ… è§£åƒåº¦ã‚’å›ºå®šã—ã¦è»½é‡åŒ–

    output_path = os.path.join(tempfile.gettempdir(), "output_hand_pose.mp4")
    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))
    stframe = st.empty()

    with mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7) as hands:
        frame_idx = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame = cv2.resize(frame, (w, h))  # âœ… è§£åƒåº¦ã‚’ç¸®å°

            if frame_idx % 2 == 0:  # âœ… 1ãƒ•ãƒ¬ãƒ¼ãƒ ãŠãã«æ¨è«–
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = hands.process(frame_rgb)

                if results.multi_hand_landmarks:
                    for hand_landmarks in results.multi_hand_landmarks:
                        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            stframe.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels="RGB")
            out.write(frame)
            frame_idx += 1

    cap.release()
    out.release()
    return output_path

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ ãˆã‚‰ã‚“ã§ã­ï¼ˆã—ã‚ƒã—ã‚“ or ã©ã†ãŒï¼‰", type=["jpg", "jpeg", "png", "mp4"])

if file is not None:
    file_type = file.type

    if "image" in file_type:
        file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

        if image is not None:
            output_image = detect_hand_image(image)
            st.image(output_image, channels="BGR", caption="âœ¨ ã“ã‚ŒãŒ ãã¿ã® ã¦ã®ã»ã­ ã ã‚ˆï¼")
            st.success("ã™ã”ã„ã­ï¼ã¦ã® ã»ã­ãŒ ã¿ãˆãŸã‚ˆ ğŸ‘")
        else:
            st.error("ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    elif "video" in file_type:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(file.read())
        tfile.flush()

        st.info("ğŸï¸ å‹•ç”»ã‚’å‡¦ç†ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
        output_video_path = detect_hand_video(tfile.name)

        st.success("âœ¨ ã¦ã® ã»ã­ã‚’ ã‘ã‚“ã—ã‚…ã¤ã—ãŸã‚ˆï¼ã™ã”ã„ã­ï¼")

        with open(output_video_path, "rb") as f:
            st.download_button(
                label="ğŸ“¥ ã‘ã‚“ã—ã‚…ã¤ã—ãŸã©ã†ãŒã‚’ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=f,
                file_name="hand_pose_output.mp4",
                mime="video/mp4"
            )
    else:
        st.error("å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚")
        
