import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import os

st.set_page_config(page_title="ã¦ã®ã»ã­ã‘ã‚“ã—ã‚…ã¤ã‚¢ãƒ—ãƒª", layout="centered")

# MediaPipe Hands
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.markdown("<h1 style='color: #4D90FE;'>ğŸ–ï¸ ã¦ã®ã»ã­ã‚’ ã¿ã¦ã¿ã‚ˆã†ï¼</h1>", unsafe_allow_html=True)
st.write("ãˆã„ãã†ã‚„ ã—ã‚ƒã—ã‚“ã‚’ ã‚¢ãƒƒãƒ—ã—ã¦ã­ã€‚ã¦ã® ã»ã­ã‚’ ã‹ãã—ã¦ãã‚Œã‚‹ã‚ˆï¼")

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ ãˆã‚‰ã‚“ã§ã­ï¼ˆã—ã‚ƒã—ã‚“ or ã©ã†ãŒï¼‰", type=["jpg", "jpeg", "png", "mp4"])

# æ¤œå‡ºé–¢æ•°
def detect_hand(image):
    with mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.7) as hands:
        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(
                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS
                )
    return image

# å‡¦ç†
if file is not None:
    file_type = file.type
    if "image" in file_type:
        file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, 1)
        output_image = detect_hand(image)
        st.image(output_image, channels="BGR", caption="âœ¨ ã“ã‚ŒãŒ ãã¿ã® ã¦ã®ã»ã­ ã ã‚ˆï¼")
        st.success("ã™ã”ã„ã­ï¼ã¦ã® ã»ã­ãŒ ã¿ãˆãŸã‚ˆ ğŸ‘")

    elif "video" in file_type:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(file.read())
        cap = cv2.VideoCapture(tfile.name)
        stframe = st.empty()

        # å‹•ç”»æƒ…å ±
        fps = cap.get(cv2.CAP_PROP_FPS)
        w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        # å‡ºåŠ›å‹•ç”»ã®æº–å‚™
        output_path = os.path.join(tempfile.gettempdir(), "output_hand_pose.mp4")
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))

        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ¤œå‡ºï¼ˆæœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
        ret, frame = cap.read()
        if ret:
            with mp_hands.Hands(static_image_mode=True) as warmup:
                _ = warmup.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

        with mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.7) as hands:
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = hands.process(frame_rgb)

                if results.multi_hand_landmarks:
                    for hand_landmarks in results.multi_hand_landmarks:
                        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                stframe.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels="RGB")
                out.write(frame)

        cap.release()
        out.release()

        st.success("âœ¨ ã¦ã® ã»ã­ã‚’ ã‘ã‚“ã—ã‚…ã¤ã—ãŸã‚ˆï¼ã™ã”ã„ã­ï¼")

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        with open(output_path, "rb") as f:
            st.download_button(
                label="ğŸ“¥ ã‘ã‚“ã—ã‚…ã¤ã—ãŸã©ã†ãŒã‚’ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=f,
                file_name="hand_pose_output.mp4",
                mime="video/mp4"
            )


